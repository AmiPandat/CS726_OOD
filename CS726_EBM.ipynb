{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "014f5df8-7f3a-4019-8d20-833b99c2ee40",
   "metadata": {},
   "source": [
    "import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26add28f-4a50-48ee-a72e-43989d950981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02521314-9bdd-4c49-8ce0-843dce95aeb7",
   "metadata": {},
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30cc5ecf-e479-48c8-867b-38c2962facb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize images to fit the model\n",
    "        transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet stats\n",
    "    ])\n",
    "    \n",
    "    # Load training and testing datasets\n",
    "    train_dataset = datasets.ImageFolder(root=os.path.join(data_dir, 'train'), transform=transform)\n",
    "    test_dataset = datasets.ImageFolder(root=os.path.join(data_dir, 'test'), transform=transform)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71efc63a-c51f-427d-8ab4-2f4ab9dc8860",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b89ad19-6009-4259-83f7-395c6e30968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # Load a pre-trained ResNet50 model\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    \n",
    "    # Replace the fully connected layer with a new one that outputs a single energy value\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(model.fc.in_features, 1),\n",
    "        nn.Flatten()\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbc16f0-0c72-4021-bc89-0335a2a24bf6",
   "metadata": {},
   "source": [
    "training and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd91966a-0ade-49ba-9cfc-36ff6662dbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss_function(outputs, labels):\n",
    "    # Example: MSE loss that expects drones to have lower energies\n",
    "    target_energies = torch.where(labels == 0, torch.zeros_like(outputs), torch.ones_like(outputs) * 1)  # drones: 0, birds: 1\n",
    "    loss = torch.mean((outputs - target_energies) ** 2)\n",
    "    return loss\n",
    "\n",
    "def train_model(model, train_loader, device, optimizer, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for data, labels in train_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = custom_loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f'Epoch {epoch+1}, Average Loss: {total_loss / len(train_loader)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae2fdf0-b1ca-4dbe-ae79-e95095e3cf63",
   "metadata": {},
   "source": [
    "Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d5b8f26-1759-499b-b62b-db45d848e5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data, labels in test_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            outputs = model(data)\n",
    "            predicted = outputs < 0.5  # Threshold for classifying as drone\n",
    "            correct += (predicted.flatten() == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy: {accuracy}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06210868-d52b-4bf8-aecd-2d671639f0a9",
   "metadata": {},
   "source": [
    "main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46c8403e-bafa-4433-94ad-a009331851bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 0.29930051786456996\n",
      "Epoch 2, Average Loss: 0.2618972112140256\n",
      "Epoch 3, Average Loss: 0.2538334256160759\n",
      "Epoch 4, Average Loss: 0.2535139743439452\n",
      "Epoch 5, Average Loss: 0.25240260032479633\n",
      "Epoch 6, Average Loss: 0.2504317952308826\n",
      "Epoch 7, Average Loss: 0.2545231468752473\n",
      "Epoch 8, Average Loss: 0.24846959114074707\n",
      "Epoch 9, Average Loss: 0.254141928014641\n",
      "Epoch 10, Average Loss: 0.2577128716393145\n",
      "Accuracy: 39.88326848249027%\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    data_dir = r'D:\\Python\\CS726_Project\\dataset_ebm1'  # Update this path to your dataset\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    train_loader, test_loader = load_data(data_dir)\n",
    "    model = create_model()\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    train_model(model, train_loader, device, optimizer, epochs=10)\n",
    "    evaluate_model(model, test_loader, device)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be94ea67-a2fe-4d61-b617-5747a8739eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_scores(model, data_loader, device):\n",
    "    model.eval()\n",
    "    scores = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data = data.to(device)\n",
    "            outputs = model(data)\n",
    "            scores.extend(outputs.cpu().numpy().flatten())  # Flatten and convert to list\n",
    "            labels.extend(target.cpu().numpy())  # Store labels to differentiate the groups later\n",
    "\n",
    "    return scores, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01cb90c3-ed2c-4bf7-8afb-a8c6e149bb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_histograms(scores, labels):\n",
    "    drone_scores = [score for score, label in zip(scores, labels) if label == 0]\n",
    "    bird_scores = [score for score, label in zip(scores, labels) if label == 1]\n",
    "\n",
    "    plt.hist(drone_scores, bins=30, alpha=0.5, label='Drones (ID)', color='blue')\n",
    "    plt.hist(bird_scores, bins=30, alpha=0.5, label='Birds (OOD)', color='red')\n",
    "    plt.xlabel('Predicted Energy Scores')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Predicted Energy Scores')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    plt.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d35e61-388c-4697-a7b7-5de2b734b08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    data_dir = r'D:\\Python\\CS726_Project\\dataset_ebm1'\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    _, test_loader = load_data(data_dir)\n",
    "    model = create_model().to(device)\n",
    "    \n",
    "    # Assuming the model is already trained and loaded\n",
    "    scores, labels = collect_scores(model, test_loader, device)\n",
    "    plot_histograms(scores, labels)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3427de-ee44-4167-b303-efcd60750e26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
