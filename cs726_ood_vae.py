# -*- coding: utf-8 -*-
"""CS726-OOD.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L-j-CHjnxj1TvzfXdGjcjbPNL-EN24lP

Data Preparation
"""

import zipfile
import os

# Specify the path to your zip file
zip_path = '/content/archive.zip'

# Specify the directory to extract to
extract_to = '/content/data'

# Create a directory if it doesn't exist
os.makedirs(extract_to, exist_ok=True)

# Unzipping the file
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_to)

print("Unzipping completed.")

!ls /content/data/BirdVsDrone/Drones
!ls /content/data/BirdVsDrone/Birds

!mkdir -p /content/data1/Birds

!mkdir -p /content/data1/Drones

!find /content/data/BirdVsDrone/Drones/AllDrones/ -type f -name '*.jpeg' -exec mv {} /content/data1/Drones/ \;

!find /content/data/BirdVsDrone/Birds/AllBirds/ -type f -name '*.jpeg' -exec mv {} /content/data1/Birds/ \;

import os
from torch.utils.data import Dataset, DataLoader
from torchvision.transforms import Compose, Resize, ToTensor
from PIL import Image

class CustomImageDataset(Dataset):
    def __init__(self, directory, transform=None):
        self.directory = directory
        self.transform = transform
        self.images = [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith(('.jpeg', '.png'))]
        print(f"Found {len(self.images)} images in {directory}")

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_name = self.images[idx]
        image = Image.open(img_name).convert('RGB')

        if self.transform:
            image = self.transform(image)

        # Return image and a dummy label (e.g., 0)
        return image, 0


# Transformation
transform = Compose([Resize((64, 64)), ToTensor()])

# Load dataset
# Assuming the paths are correct
drone_dataset = CustomImageDataset('/content/data1/Drones', transform=transform)
bird_dataset = CustomImageDataset('/content/data1/Birds', transform=transform)

drone_loader = DataLoader(drone_dataset, batch_size=10, shuffle=True)
bird_loader = DataLoader(bird_dataset, batch_size=10, shuffle=True)

drone_loader = DataLoader(drone_dataset, batch_size=10, shuffle=True)
bird_loader = DataLoader(bird_dataset, batch_size=10, shuffle=True)
def show_images(loader):
    data = next(iter(loader))
    img = data[0].permute(1, 2, 0)
    plt.imshow(img)
    plt.show()

show_images(drone_loader)
show_images(bird_loader)

"""Create VAE model"""

# import torch
# from torch import nn
# from torch.nn import functional as F

# class VAE(nn.Module):
#     def __init__(self):
#         super(VAE, self).__init__()

#         # Encoder
#         self.fc1 = nn.Linear(64*64*3, 400)
#         self.fc21 = nn.Linear(400, 20)  # Mean
#         self.fc22 = nn.Linear(400, 20)  # Log variance

#         # Decoder
#         self.fc3 = nn.Linear(20, 400)
#         self.fc4 = nn.Linear(400, 64*64*3)

#     def encode(self, x):
#         h1 = F.relu(self.fc1(x))
#         return self.fc21(h1), self.fc22(h1)

#     def reparameterize(self, mu, logvar):
#         std = torch.exp(0.5 * logvar)
#         eps = torch.randn_like(std)
#         return mu + eps * std

#     def decode(self, z):
#         h3 = F.relu(self.fc3(z))
#         return torch.sigmoid(self.fc4(h3))

#     def forward(self, x):
#         mu, logvar = self.encode(x.view(-1, 64*64*3))
#         z = self.reparameterize(mu, logvar)
#         return self.decode(z), mu, logvar

"""CAE"""

import torch
import torch.nn as nn
import torch.nn.functional as F

class ConvAutoencoder(nn.Module):
    def __init__(self):
        super(ConvAutoencoder, self).__init__()

        # Encoder
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),  # output: [16, 32, 32]
            nn.ReLU(),
            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),  # output: [32, 16, 16]
            nn.ReLU(),
            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),  # output: [64, 8, 8]
            nn.ReLU(),
            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),  # output: [128, 4, 4]
            nn.ReLU(),
            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),  # output: [256, 2, 2]
            nn.ReLU()
        )

        # Decoder
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),  # output: [128, 4, 4]
            nn.ReLU(),
            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),  # output: [64, 8, 8]
            nn.ReLU(),
            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),  # output: [32, 16, 16]
            nn.ReLU(),
            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),  # output: [16, 32, 32]
            nn.ReLU(),
            nn.ConvTranspose2d(16, 3, kernel_size=3, stride=2, padding=1, output_padding=1),  # output: [3, 64, 64]
            nn.Sigmoid()
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

# Sample input to test the model's output dimensions
test_input = torch.rand(1, 3, 64, 64)  # Change the size here if your actual input has a different size
model = ConvAutoencoder()
output = model(test_input)
print("Output shape:", output.shape)

"""Train CAE"""

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = ConvAutoencoder().to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
criterion = nn.MSELoss()

model.train()
num_epochs = 20
for epoch in range(num_epochs):
    total_loss = 0
    for data, _ in drone_loader:
        data = data.to(device)
        optimizer.zero_grad()
        recon = model(data)
        loss = criterion(recon, data)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    print(f'Epoch {epoch+1}, Loss: {total_loss/len(drone_loader)}')

# def loss_function(recon_x, x, mu, logvar):
#     BCE = F.binary_cross_entropy(recon_x, x.view(-1, 64*64*3), reduction='sum')
#     KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
#     return BCE + KLD

"""Train VAEs"""

# from torch.optim import Adam

# device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# model = VAE().to(device)
# optimizer = Adam(model.parameters(), lr=1e-5)
# data_loader = drone_loader  # Your DataLoader for drone images

# model.train()
# num_epochs = 15
# for epoch in range(num_epochs):
#     for batch_idx, (data, _) in enumerate(data_loader):
#         data = data.to(device)
#         optimizer.zero_grad()
#         recon_batch, mu, logvar = model(data)
#         loss = loss_function(recon_batch, data, mu, logvar)
#         loss.backward()
#         optimizer.step()
#         if batch_idx % 10 == 0:
#             print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(data_loader)}], Loss: {loss.item()/len(data)}')

"""CAE OOD testing"""

def test_ood(data_loader, model):
    model.eval()
    ood_scores = []
    with torch.no_grad():
        for data, _ in data_loader:
            data = data.to(device)

def calculate_reconstruction_error(data_loader, model):
    model.eval()
    reconstruction_errors = []

    with torch.no_grad():
        for data, _ in data_loader:
            data = data.to(device)
            reconstructed = model(data)
            mse = F.mse_loss(reconstructed, data, reduction='none')
            mse = mse.view(mse.size(0), -1).mean(dim=1)
            reconstruction_errors.extend(mse.cpu().numpy())

    return reconstruction_errors

drone_errors = calculate_reconstruction_error(drone_loader, model)

bird_errors = calculate_reconstruction_error(bird_loader, model)

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 5))
plt.hist(drone_errors, bins=50, alpha=0.7, label='In-Distribution (Drones)')
plt.hist(bird_errors, bins=50, alpha=0.7, label='Out-of-Distribution (Birds)')
plt.xlabel('Reconstruction Error')
plt.ylabel('Frequency')
plt.legend()
plt.show()

import numpy as np
threshold = np.percentile(drone_errors, 95)  # Set threshold at 95th percentile of in-distribution errors
print("Threshold for OOD detection:", threshold)

# Classify as OOD based on the threshold
ood_labels = [error > threshold for error in bird_errors]
print("Detected OOD samples:", sum(ood_labels))

import matplotlib.pyplot as plt
import numpy as np

# Assume `drone_errors` and `bird_errors` are your lists of errors
plt.figure(figsize=(12, 6))
plt.hist(drone_errors, bins=50, alpha=0.5, label='Drone (ID)', color='blue')
plt.hist(bird_errors, bins=50, alpha=0.5, label='Bird (OOD)', color='red')
plt.axvline(x=threshold, color='green', linestyle='dashed', linewidth=2, label='Threshold')
plt.legend()
plt.title('Reconstruction Error Distribution')
plt.xlabel('Reconstruction Error')
plt.ylabel('Frequency')
plt.show()

import numpy as np

# Assuming 'drone_errors' and 'bird_errors' are arrays or lists of reconstruction errors
# And 'threshold' is the value  calculated or chosen
# True labels: 0 for drone (ID) and 1 for bird (OOD)
drone_labels = np.zeros_like(drone_errors)
bird_labels = np.ones_like(bird_errors)

# Combine errors and labels
all_errors = np.concatenate((drone_errors, bird_errors))
all_labels = np.concatenate((drone_labels, bird_labels))

# Predictions based on threshold
predictions = (all_errors > threshold).astype(int)

# Calculate TP and FP
TP = np.sum((predictions == 1) & (all_labels == 1))
FP = np.sum((predictions == 1) & (all_labels == 0))

# Calculate precision
precision = TP / (TP + FP) if (TP + FP) > 0 else 0

print(f'Precision: {precision:.4f}')

# True positives (TP) - OOD correctly identified
# False negatives (FN) - OOD incorrectly identified as ID
# True negatives (TN) - ID correctly identified
# False positives (FP) - ID incorrectly identified as OOD

# Recall calculation
FN = np.sum((predictions == 0) & (all_labels == 1))
recall = TP / (TP + FN) if (TP + FN) > 0 else 0

# Accuracy calculation
TN = np.sum((predictions == 0) & (all_labels == 0))
accuracy = (TP + TN) / len(all_labels) if len(all_labels) > 0 else 0

print(f'Recall: {recall:.4f}')
print(f'Accuracy: {accuracy:.4f}')

"""VAE OOD testing"""

def test_ood(data_loader, model):
    model.eval()
    ood_scores = []
    with torch.no_grad():
        for data, _ in data_loader:
            data = data.to(device)
            recon, _, _ = model(data)
            recon_error = F.mse_loss(recon, data.view(-1, 64*64*3), reduction='none').sum(1).mean().item()
            ood_scores.append(recon_error)
    return ood_scores

bird_loader = DataLoader(bird_dataset, batch_size=10, shuffle=False)  # Assuming bird_dataset is set up similarly
bird_ood_scores = test_ood(bird_loader, model)
print("Average OOD score for bird images:", sum(bird_ood_scores) / len(bird_ood_scores))